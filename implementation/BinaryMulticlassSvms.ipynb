{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d10712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is used for Task 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c396a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import exposure\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import resize\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.filters import prewitt_h, prewitt_v\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "pca = PCA(100)\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9eb11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method reads through the 3000 images provided and applies two transformations:\n",
    "#     1. HOG transformation\n",
    "#     2. PCA dimensionality reduction\n",
    "# Finall the result is saved to a file to avoid repeating this step\n",
    "def pre_process_data_hog_pca():\n",
    "    if os.path.isfile('../dataset/X_HOG_PCA.pickle'):\n",
    "        print('Started reading from files')\n",
    "        X = pd.read_pickle('../dataset/X_HOG_PCA.pickle')\n",
    "        print('Finished reading from files')\n",
    "        return X\n",
    "\n",
    "    df = pd.read_csv('../dataset/label.csv')\n",
    "\n",
    "    X = pd.DataFrame()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img_gray = imread('../dataset/image/' + row['file_name'], as_gray=True)\n",
    "\n",
    "        fd, hog_image = hog(img_gray, orientations=9, pixels_per_cell=(16, 16),\n",
    "                            cells_per_block=(2, 2), visualize=True, multichannel=False)\n",
    "\n",
    "        data_rescaled = scaler.fit_transform(hog_image)\n",
    "\n",
    "        img_transformed = pca.fit_transform(data_rescaled)\n",
    "\n",
    "#         Show transformation example\n",
    "        if(index == 0):\n",
    "            # Start plot section\n",
    "            hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "            _, axs = plt.subplots(1, 2, figsize=(12, 12))\n",
    "            axs = axs.flatten()\n",
    "            imgs = [img_gray, hog_image_rescaled]\n",
    "            for img, ax in zip(imgs, axs):\n",
    "                ax.imshow(img)\n",
    "            plt.show()\n",
    "            # End plot section\n",
    "\n",
    "        features = np.reshape(img_transformed, (512 * 100))\n",
    "        if np.any(np.isnan(features)):\n",
    "            print('features creating nans')\n",
    "\n",
    "        X = X.append(pd.Series(features).T, ignore_index=True)\n",
    "        print(\"\\rCompleted {:.2f}\".format((index / df.shape[0]) * 100), end=\"\")\n",
    "\n",
    "    X.to_pickle('../dataset/X_HOG_PCA.pickle')\n",
    "    return X\n",
    "\n",
    "# Reads the input and output to determine which classes are underrepresented, then augments and creates new\n",
    "# data points to balance the datasets using SMOTE\n",
    "def resolve_imbalances_smote(X, Y):\n",
    "    print(Counter(Y))\n",
    "    oversample = SMOTE()\n",
    "    X, Y = oversample.fit_resample(X, Y)\n",
    "    print(Counter(Y))\n",
    "    return X, Y\n",
    "\n",
    "# Extracts labels for binary classification by making all non-tumor labels = tumor then converts to binary\n",
    "def y_binary():\n",
    "    df = pd.read_csv('../dataset/label.csv')\n",
    "    return (df['label'] != 'no_tumor').astype(int)\n",
    "\n",
    "# Extracts all labels and transforms to numeric representation\n",
    "def y_multiclass():\n",
    "    df = pd.read_csv('../dataset/label.csv')\n",
    "    le.fit(df['label'])\n",
    "    return le.transform(df['label'])\n",
    "\n",
    "# Converts numeric represnetation of labels back to original form\n",
    "def invert_multiclass(Y):\n",
    "    return le.inverse_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e27eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_tuned_predict(x_train, y_train, x_test, y_test):\n",
    "#     Grid Search tuning, results already selected as linear, C=0.05\n",
    "#     param_grid = {'C': [0.025, 0.05, 0.1, 0.25], 'kernel': ['linear', 'rbf']}\n",
    "#     grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)\n",
    "#     grid.fit(x_train, y_train)\n",
    "\n",
    "    svc = SVC(C=0.05, kernel='linear')\n",
    "    svc.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = svc.predict(x_test)\n",
    "    y_train_pred = svc.predict(x_train)\n",
    "\n",
    "    print('Accuracy on SVM training set: ' + str(accuracy_score(y_train, y_train_pred)))\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "    print('Accuracy on SVM test set: ' + str(accuracy_score(y_test, y_pred)))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd52a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading from files\n",
      "Finished reading from files\n",
      "Counter({1: 2546, 0: 454})\n",
      "Counter({1: 2546, 0: 2546})\n"
     ]
    }
   ],
   "source": [
    "X = pre_process_data_hog_pca()\n",
    "Y = y_binary()\n",
    "\n",
    "X, Y = resolve_imbalances_smote(X, Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9029d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary results\n",
      "Accuracy on SVM training set: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1918\n",
      "           1       1.00      1.00      1.00      1901\n",
      "\n",
      "    accuracy                           1.00      3819\n",
      "   macro avg       1.00      1.00      1.00      3819\n",
      "weighted avg       1.00      1.00      1.00      3819\n",
      "\n",
      "Accuracy on SVM test set: 0.9874312647289867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       628\n",
      "           1       1.00      0.98      0.99       645\n",
      "\n",
      "    accuracy                           0.99      1273\n",
      "   macro avg       0.99      0.99      0.99      1273\n",
      "weighted avg       0.99      0.99      0.99      1273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('binary results')\n",
    "svm_tuned_predict(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7b4f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading from files\n",
      "Finished reading from files\n",
      "Counter({0: 860, 1: 855, 3: 831, 2: 454})\n",
      "Counter({1: 860, 2: 860, 0: 860, 3: 860})\n",
      "multiclass results\n",
      "Accuracy on SVM training set: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       652\n",
      "           1       1.00      1.00      1.00       623\n",
      "           2       1.00      1.00      1.00       645\n",
      "           3       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           1.00      2580\n",
      "   macro avg       1.00      1.00      1.00      2580\n",
      "weighted avg       1.00      1.00      1.00      2580\n",
      "\n",
      "Accuracy on SVM test set: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63       208\n",
      "           1       0.68      0.55      0.61       237\n",
      "           2       0.90      0.93      0.92       215\n",
      "           3       0.82      0.87      0.84       200\n",
      "\n",
      "    accuracy                           0.75       860\n",
      "   macro avg       0.75      0.76      0.75       860\n",
      "weighted avg       0.75      0.75      0.75       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = pre_process_data_hog_pca()\n",
    "Y = y_multiclass()\n",
    "\n",
    "X, Y = resolve_imbalances_smote(X, Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "\n",
    "print('multiclass results')\n",
    "svm_tuned_predict(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17404167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
